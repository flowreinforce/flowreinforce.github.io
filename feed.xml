<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://flowreinforce.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://flowreinforce.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-24T14:55:01+00:00</updated><id>https://flowreinforce.github.io/feed.xml</id><title type="html">Flow Matching Policy Gradients</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Flow Plot</title><link href="https://flowreinforce.github.io/test-plot" rel="alternate" type="text/html" title="Flow Plot"/><published>2025-06-24T00:00:00+00:00</published><updated>2025-06-24T00:00:00+00:00</updated><id>https://flowreinforce.github.io/test-plot</id><content type="html" xml:base="https://flowreinforce.github.io/test-plot"><![CDATA[<div class="l-page"> <iframe src="/assets/plotly/flow_sde_plot.html" frameborder="0" scrolling="no" height="500px" width="120%" style="margin-left: -10%;"></iframe> </div>]]></content><author><name></name></author><category term="distill"/><category term="formatting"/><summary type="html"><![CDATA[Try it out!]]></summary></entry><entry><title type="html">Flow Matching Policy Gradients</title><link href="https://flowreinforce.github.io/" rel="alternate" type="text/html" title="Flow Matching Policy Gradients"/><published>2025-06-20T00:00:00+00:00</published><updated>2025-06-20T00:00:00+00:00</updated><id>https://flowreinforce.github.io/fm-pg</id><content type="html" xml:base="https://flowreinforce.github.io/"><![CDATA[<div style="text-align: center; margin-bottom: 20px;"> <a href="https://mcallisterdavid.com/" style="text-decoration: none; margin: 18px 18px; font-weight: bold;"> David McAllister* </a> <a href="https://songweige.github.io" style="text-decoration: none; margin: 18px 18px; font-weight: bold;"> Songwei Ge* </a> <a href="https://brentyi.github.io/" style="text-decoration: none; margin: 18px 18px; font-weight: bold;"> Brent Yi* </a> <a href="https://chungmin99.github.io" style="text-decoration: none; margin: 0 10px; font-weight: bold;"> Chung Min Kim </a> <a href="https://ethanweber.me" style="text-decoration: none; margin: 0 10px; font-weight: bold;"> Ethan Weber </a> <a href="https://hongsukchoi.github.io/" style="text-decoration: none; margin: 18px 18px; font-weight: bold;"> Hongsuk Choi </a> <a href="https://havenfeng.github.io" style="text-decoration: none; margin: 0 10px; font-weight: bold;"> Haiwen Feng </a> <a href="https://people.eecs.berkeley.edu/~kanazawa/" style="text-decoration: none; margin: 0 10px; font-weight: bold;"> Angjoo Kanazawa </a> </div> <div style="text-align: center; margin-bottom: 20px;"> <a href="https://arxiv.org/pdf/2501.05450" class="btn btn-lg z-depth-0" role="button" style="text-decoration: none; border: 1px solid #ccc; margin: 0 5px; padding: 10px 20px;"> <i class="fas fa-file-pdf"></i> Paper </a> <a href="https://arxiv.org/abs/2501.05450" class="btn btn-lg z-depth-0" role="button" style="text-decoration: none; border: 1px solid #ccc; margin: 0 5px; padding: 10px 20px;"> <i class="ai ai-arxiv"></i> arXiv </a> </div> <p>Flow models have become the go-to approach to model distributions in continuous space. They soak up data with a simple, scalable denoising objective and now represent the state-of-the art in generating images, videos, audio and, more recently, robot action. However, they’re still not widely used for learning from rewards with reinforcement learning.</p> <p>To perform RL in continuous spaces, practitioners typically train far simpler Gaussian policies, which represent a single, ellipsoidal mode of the action distribution. Flow-based policies can capture complex, multimodal action distributions, but they are primarily trained in a supervised manner with behavior cloning (BC). We show that it’s possible to train RL policies using flow matching, the framework behind modern diffusion and flow models, to benefit from its expressivity.</p> <p>We introduce <b>Flow Policy Optimization</b> (FPO), a new algorithm to train RL policies with flow matching. It can train expressive flow policies from only rewards. We find its particularly useful to learn underconditioned policies, like humanoid locomotion with simple joystick commands.</p> <p>We approached this project as researchers primarily familiar with diffusion models. While working on <a href="https://videomimic.net">VideoMimic</a>, we felt limited by the expressiveness of Gaussian policies and thought diffusion could help. In this blog post, we’ll explain how we connect flow matching and on-policy RL in a way that makes sense without an extensive RL background.</p> <h2 id="flow-matching">Flow Matching</h2> <p>Flow matching<d-cite key="lipman2023flowmatchinggenerativemodeling"></d-cite> optimizes a model to transform a simple distribution (e.g., the Gaussian distribution) into a complex one through a multi-step mapping called the marginal flow. We expand on the marginal flow in more detail in another blog post for <a href="https://decentralizeddiffusion.github.io">Decentralized Diffusion Models</a>.</p> <p>The flow smoothly directs a particle $x_t$ to the data distribution, so integrating a particle’s position across time according to the flow yields a sample from the data distribution. Equivalently, sampling is the process of solving an ordinary differential equation (the flow), which we can do deterministically or with stochastic “churn” every step.</p> <p>We can actually calculate the marginal flow <em>analytically</em>, which we do in real-time in the plot below. We added interactive control over the data distribution and sampling stochasticity, so try messing with it!</p> <div class="l-page"> <div class="plotly-responsive-container"> <iframe src="/assets/plotly/flow_sde_plot.html" frameborder="0" scrolling="no" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; touch-action: manipulation;" allow="accelerometer; gyroscope"></iframe> </div> </div> <p>Each particle above represent an $x_t$ noisy latent that gets iteratively denoised as the time is integrated from zero to one. Drag the control points of the modes on the right to see how the underlying PDF and the particle trajectories change. Notice how the probability mass flows smoothly from the initial noise to form two distinct modes. The multi-step mapping is the magic that lets flow models transform a simple, tractable distribution into one of arbitrary complexity.</p> <p>While it’s possible to interactively compute this flow in 1D, it becomes intractable over large datasets in high dimensional space. Instead, we use flow matching, which compresses the marginal flow into a neural network through a simple reconstruction objective.</p> <p>Flow matching perturbs a clean data sample with Gaussian noise then tasks the model with reconstructing the sample by predicting the velocity, which is the derivative of $x_t$’s position <em>w.r.t.</em> time. In expectation over a fixed dataset, this optimization recovers the marginal flow for any $x_t$. Integrating $x_t$’s position across time according to a well-trained model’s velocity prediction will recover a sample from the data distribution.</p> <div class="l-body" style="text-align: center; margin-top: -4%; margin-bottom: -4%;"> <img src="/assets/img/fpo/flow_matching.svg" alt="DDM Overview" style="margin-left: -5%; width: 110%; height: auto; clip-path: inset(0px 0 0px 0);"/> </div> <div class="caption" style="margin-top: 0px; margin-bottom: 2%;"> Flow matching the velocity prediction $v_t(x_t)$ to the conditional flow $u_t(x_t|x)$. </div> <p>Geometrically, the marginal flow points to a <em>weighted-average</em> of the data where the weights are a function of the timestep and distance from $x_t$ to each data point. You can see the particles follow the marginal flow exactly in the plot above when stochasticity is turned off. At a high level, flow matching learns to point the model’s flow field, $v_t(x_t)$, to the data distribution.</p> <p>Flow matching has statistical significance too. Instead of computing exact flow likelihoods (expensive and unstable), it optimizes a lower bound called the Evidence Lower Bound (ELBO)<d-cite key="kingma2023understandingdiffusionobjectiveselbo"></d-cite>. Increasing the ELBO pushes the model toward higher likelihoods without computing them directly. In the limit, the flow model will sample exactly from the probability distribution of the dataset. So if you’ve learned the flow function well, you’ve learned the underlying structure of the data.</p> <p><b>TLDR: Flowing toward a data point increases its likelihood under the model.</b></p> <h2 id="on-policy-rl-sample-score-reinforce">On-Policy RL: Sample, Score, Reinforce</h2> <p>On-policy reinforcement learning follows a basic core loop: sample from your policy, score each action with rewards, then make high-reward actions more likely. Rinse and repeat.</p> <p>This procedure climbs the policy gradient—the gradient of expected cumulative reward. Your model collects “experience” by sampling its learned distribution, sees which samples are most advantageous, and adjusts to perform similar actions more often.</p> <p>On-policy RL can be cast as search iteratively distilled into a model. The policy “happens upon” good behaviors through exploration, then reinforces them. Over time, it discovers the patterns in the random successes and develops reliable strategies. You can start from a pretrained model and continue training with RL to explore within a pruned prior distribution rather than at random. This is the dominant approach to upcycle LLMs for preference alignment<d-cite key="ouyang2022traininglanguagemodelsfollow"></d-cite> and mathematical reasoning<d-cite key="deepseekai2025deepseekr1incentivizingreasoningcapability"></d-cite>.</p> <h3 id="illustrative-example">Illustrative Example</h3> <p>We use the toy cartpole task from DMControl<d-cite key="tassa2018deepmindcontrolsuite"></d-cite> for clear illustration. The goal is to move a cart along a rail to balance an attached pole vertically. Here’s how this manifests as an RL loop:</p> <ol> <li>Sample an action from your model’s state-conditional distribution then simulate a step of physics. Do this back and forth in succession over a time horizon (rollouts).</li> <li>Score each sequence with rewards for each timestep (“how vertical is the pole?”).</li> <li>Train your model to boost the likelihood of actions that lead to high-reward sequences.</li> </ol> <ul> <li>Repeat above until your model reliably balances the pole.</li> </ul> <p><b>Sample and score rollouts:</b></p> <div style="margin-left: -2%; margin-bottom: -4%; width: 104%; height: auto; clip-path: inset(0px 0 0px 0);"> <figure> <video src="/assets/video/cartpole_reward_composite.mp4" class="img-fluid rounded" width="100%" height="100%" autoplay="" loop="" muted=""/> </figure> </div> <div class="caption"> On-policy RL samples multiple rollouts of actions then scores them according to the reward. In this case, only one (leftmost) rollout successfully balances the pole across the whole time horizon. </div> <p><b>Calculate each advantage and estimate the policy gradient:</b></p> <p>From the rewards, we estimate advantages. These can be viewed as the reward over time (return) normalized <em>w.r.t.</em> the expected return. This expectation is what the critic learns in PPO<d-cite key="schulman2017proximalpolicyoptimizationalgorithms"></d-cite> or computed as the average of a group’s rewards in GRPO<d-cite key="shao2024deepseekmathpushinglimitsmathematical"></d-cite>.</p> <div style="margin-left: -2%; margin-bottom: -4%; width: 104%; height: auto; clip-path: inset(0px 0 0px 0);"> <figure> <video src="/assets/video/cartpole_advantage_composite.mp4" class="img-fluid rounded" width="100%" height="100%" autoplay="" loop="" muted=""/> </figure> </div> <div class="caption"> Advantages are lower-variance estimates of action "goodness" than rewards. There is a design space to estimating advantages, but one way to think of them is as normalized rewards. </div> <p></p> <p>Given the advantages, we train the model on each data point with a gradient update scaled by its corresponding advantage. So, if the advantage is negative, it will become less likely. Postive advantage, more likely.</p> <p>Typically, the policy gradient is computed in discrete space or using Gaussian likelihoods. Flow Policy Optimization extends the policy gradient to flow models, which introduces some important details we discuss in the following sections.</p> <h2 id="flow-matching-policy-gradients">Flow Matching Policy Gradients</h2> <p>To reiterate, the goal of on-policy RL is simple: increase the likelihood of high-reward actions. Meanwhile, flow matching naturally increases likelihoods by redirecting probability flow toward training samples. This makes our objective clear—<b>redirect the flow toward high reward actions</b>.</p> <p>In the limit of perfect optimization, flow matching assigns probabilities according to the frequency of samples in your training set. Since we’re using RL, that “training set” is dynamically generated from the model each epoch.</p> <p>Advantages make the connection between synthetic data generation and on-policy RL explicit. In RL, we calculate the advantage of each sampled action, a quantity that indicates how much better it was than expected. These advantages are centered around zero to reduce variance: positive for better-than-expected actions, negative for worse. Advantages then become a <em>loss weighting</em> in the policy gradient. As a simple example, if an action is very advantageous, the model encounters a scaled-up loss on it and learns to boost it aggressively.</p> <div class="l-body" style="text-align: center;"> <img src="/assets/img/fpo/policy_grad.svg" alt="DDM Overview" style="width: 100%; height: auto; margin-top: 2%;"/> </div> <div class="caption"> The policy gradient resembles a standard log-likelihood supervised learning gradient on synthetic samples with the loss scaled by the reward or advantage (both are valid). </div> <p>Zero-mean advantages are fine for RL in discrete spaces because a negative advantage simply pushes down the logit of a suboptimal action, and the softmax ensures that the resulting action probabilities remain valid and non-negative. Flow matching, however, learns probability flows to sample from a training data distribution. These are nonnegative by construction, so negative loss weights break this clean interpretation.</p> <p>There’s a simple solution: make the advantages nonnegative. Shifting advantages by a constant doesn’t change the policy gradient. In fact, this is the mathematical property that lets us use advantages instead of raw rewards in the first place. Here’s how we can understand non-negative advantages in the flow matching framework:</p> <div class="l-body" style="text-align: center;"> <img src="/assets/img/fpo/marginal_flow_fpo.svg" alt="DDM Overview" style="width: 94%; height: auto; margin-top: 2%;"/> </div> <div class="caption"> The marginal flow is a linear combination of the (conditional) flow to each data point. The weighting of each path scales with probability of drawing the data point from the dataset, $q(x)$. </div> <p>Advantages manifest as loss-weighting, which can be intuitively expressed in the marginal flow framework. The marginal flow is the weighted average of the paths (the $u_t$’s) from the current noisy particle, $x_t$, to each data point $x$. The paths are also weighed by $q(x)$, the probability of drawing $x$ from your training set. This is typically a constant $\frac{1}{N}$ for a dataset of size $N$, assuming every data point is unique. Loss weights are equivalent to altering the frequency of the data points in your training set. If the loss for a data point is scaled by a factor of 2, its equivalent to that data point showing up twice in the train set.</p> <h3 id="flow-policy-optimization">Flow Policy Optimization</h3> <p>Now, we can get a complete picture of our algorithm that connects flow matching and reinforcement learning: Flow Policy Optimization. FPO follows a three-step loop:</p> <p><b>1.</b> Generate actions from your flow model using your choice of sampler</p> <p><b>2.</b> Score them with rewards and compute advantages</p> <p><b>3.</b> Flow match (add noise and reconstruct) on the actions with an advantage-weighed loss</p> <p>This procedure boosts the likelihood of actions that achieve high reward while preserving the desirable properties of flow models—multimodality, expressivity and the improved exploration that stems from them. Since FPO uses flow matching as its fundamental primitive, FPO-trained policies inherit the body of techniques developed for flow and diffusion models. These include guidance<d-cite key="ho2022classifierfreediffusionguidance"></d-cite><d-cite key="dhariwal2021diffusionmodelsbeatgans"></d-cite> for conditioning and Mean Flows<d-cite key="geng2025meanflowsonestepgenerative"></d-cite> for efficient sampling.</p> <p>We visualize the three-step inner loop in the following interactive plot. We recommend viewing this on desktop. The red trace curve on the right determines the reward for different actions along the y-axis. It’s controllable, drag the control points around to shape the reward function! The plot shows how FPO optimizes a flow-based policy to maximize the specified reward. It follows the three following stages that line up with label above the plot:</p> <p><b>First,</b> sample actions from the flow-based policy. At the first iteration, this will be whatever the model is initialized to (or two arbitrary modes in the plot below).</p> <p><b>Second,</b> for each sampled data point, multiply its influence by the reward. We do a k-means approximation of the resulting distribution for illustration and display it in the blue trace between the heatmap and red reward trace.</p> <p><b>Third,</b> redirect the flow according to this advantage-weighed distribution. In a real model, this happens by optimizing the FPO ratio just like how standard PPO optimizes its likelihood ratio.</p> <p>This represents <em>one epoch</em> of Flow Policy Optimization. The flow has been updated to sample higher-reward actions and we can repeat to continue climbing the policy gradient. The plot does this automatically, and you can reset it with the amber color reload button.</p> <div class="l-page"> <div class="plotly-responsive-container"> <iframe src="/assets/plotly/advantage_flow_plot.html" frameborder="0" scrolling="no" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; touch-action: manipulation;" allow="accelerometer; gyroscope"></iframe> </div> </div> <p>This is a pretty realistic analytical simulation of the FPO loop. It’s missing one major component though, which is the trust region constraint<d-cite key="schulman2017trustregionpolicyoptimization"></d-cite>. This helps the optimization remain on-policy after multiple gradient steps per epoch. We encourage you to check out the paper to see how we implement this mechanism and for a more mathematical explanation of the algorithm.</p> <h2 id="fpo-in-action">FPO In Action</h2> <p>We include a few video examples of FPO working on a range of control tasks. These demonstrate FPO’s advantage over Gaussian policies in learning multimodal action distributions through under-conditioned humanoid control. With only root-level commands, FPO successfully trains walking policies from scratch, while standard Gaussian policies fail to discover viable behaviors. [also Brent here]</p> <div style="display: flex; gap: 10px; margin-left: -5%; width: 110%;"> <div style="flex: 1;"> <figure> <video src="/assets/video/results/hongsuk_1.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" loop="" muted=""/> </figure> </div> <div style="flex: 1;"> <figure> <video src="/assets/video/results/hongsuk_2.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" loop="" muted=""/> </figure> </div> </div> <div class="caption" style="margin-left: -2%; margin-top: -3%; width: 104%;"> [Brent add caption.] </div> <p>Polices trained with FPO are robust to rough terrains for DeepMimic<d-cite key="Peng_2018"></d-cite>-style motion tracking. We show a couple examples:</p> <div style="display: flex; gap: 10px; margin-left: -5%; margin-top: -3%; width: 110%;"> <div style="flex: 1;"> <figure> <video src="/assets/video/results/tap_dance.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" loop="" muted=""/> </figure> </div> <div style="flex: 1;"> <figure> <video src="/assets/video/results/dancing.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" loop="" muted=""/> </figure> </div> </div> <div class="caption" style="margin-left: -2%; margin-top: -3%; width: 104%;"> Trained with terrain randomization, FPO walks stably across unseen procedurally generated rough ground. </div> <p>It’s not a RL algorithm paper without half cheetah! We compare quanitatively to Gaussian policies and denoising MDPs in the main paper. Here are some success on this task:</p> <div style="display: flex; gap: 10px; margin-left: -5%; width: 110%;"> <div style="flex: 1;"> <figure> <video src="/assets/video/results/cheetah_1.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" loop="" muted=""/> </figure> </div> <div style="flex: 1;"> <figure> <video src="/assets/video/results/cheetah_2.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" loop="" muted=""/> </figure> </div> <div style="flex: 1;"> <figure> <video src="/assets/video/results/cheetah_3.mp4" class="img-fluid rounded" width="100%" height="auto" autoplay="" loop="" muted=""/> </figure> </div> </div> <div class="caption" style="margin-left: -2%; width: 104%; margin-top: -3%;"> We show rollouts from our policy trained for the DeepMind Control task, CheetahRun, using FPO. </div> <h2 id="acknowledgements">Acknowledgements</h2> <p>We thank Qiyang (Colin) Li, Oleg Rybkin, Lily Goli and Michael Psenka for helpful discussions and feedback on the manuscript. We thank Arthur Allshire, Tero Karras, Miika Aittala, Kevin Zakka and Seohong Park for insightful input and feedback on implementation details and the broader context of this work.</p>]]></content><author><name></name></author><category term="distill"/><category term="formatting"/><summary type="html"><![CDATA[Simple Online Reinforcement Learning with Flow Matching]]></summary></entry><entry><title type="html">Decentralized Diffusion Models</title><link href="https://flowreinforce.github.io/decentralized-diffusion" rel="alternate" type="text/html" title="Decentralized Diffusion Models"/><published>2025-01-09T00:00:00+00:00</published><updated>2025-01-09T00:00:00+00:00</updated><id>https://flowreinforce.github.io/decentralized-diffusion</id><content type="html" xml:base="https://flowreinforce.github.io/decentralized-diffusion"><![CDATA[<div style="text-align: center; margin-bottom: 20px;"> <a href="https://arxiv.org/pdf/2501.05450" class="btn btn-lg z-depth-0" role="button" style="text-decoration: none; border: 1px solid #ccc; margin: 0 5px; padding: 10px 20px;"> <i class="fas fa-file-pdf"></i> Paper </a> <a href="https://arxiv.org/abs/2501.05450" class="btn btn-lg z-depth-0" role="button" style="text-decoration: none; border: 1px solid #ccc; margin: 0 5px; padding: 10px 20px;"> <i class="ai ai-arxiv"></i> arXiv </a> </div> <div class="fake-img l-body" style="margin-bottom: 0;"> <img src="/assets/img/decentralized_diffusion/teaser_images.jpg" alt="DDM Overview" style="width: 100%; height: auto;"/> </div> <div class="caption" style="margin-top: 5px;"> Some samples from our largest Decentralized Diffusion Model, pretrained with just eight independent GPU nodes in less than a week. </div> <p>State of the art image and video diffusion models train on thousands of GPUs. They distribute computation then synchronize gradients across them at each optimization step. This incurs a massive networking load, which means that training clusters must live in centralized facilities with specialized networking hardware and enormous power delivery systems.</p> <p>This is cost-prohibitive. Academic labs can’t build specialized clusters with custom networking fabrics. Even large companies struggle as they hit fundamental limits on power delivery and networking bandwidth when scaling to many thousands of GPUs. In both cases, networking is the critical bottleneck: training clusters need constant, high-bandwidth communication throughout the entire system. A segmented network load where independent clusters communicate internally but not among each other makes it possible to use compute where it’s available, whether in different datacenters or across the internet.</p> <p><b>Decentralized Diffusion Models</b> (DDMs) tackle this problem. Our new method trains a series of expert diffusion models, each in communication isolation from one another. This means we can train them in different locations and on different hardware. At inference time, they ensemble through a lightweight learned router. We show that this ensemble collectively optimizes the same objective as a single diffusion model trained over the whole dataset (a monolithic model). It even outperforms monolithic diffusion models FLOP-for-FLOP, leveraging sparse computation at train and test time. Crucially, DDMs scale gracefully to billions of parameters and produce great results with reduced pretraining budgets. See some results below from a model pretrained with just eight independent GPU nodes in less than a week. </p> <p>In this post, we present a simple, geometrically intuitive view on diffusion and flow models from which Decentralized Diffusion Models arrive naturally. We also highlight their compromise-free performance and implications for training hardware. DDMs make possible <b>simpler training systems</b> that produce <b>better models</b>.</p> <h2 id="simple-intuitions-for-diffusion-and-flow-models">Simple Intuitions for Diffusion and Flow Models</h2> <div class="l-body"> <iframe src="/assets/plotly/plot_three.html" frameborder="0" scrolling="no" height="620px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <div class="caption"> <b>Diffusion models can be geometrically intuitive.</b> We aim to show some of these ideas in this post. </div> <p>Diffusion models and rectified flows can be seen as special cases of flow matching<d-cite key="lipman2023flowmatchinggenerativemodeling"></d-cite>, so we use the FM framework to explain DDMs. Most perspectives on diffusion models and flow matching focus on the forward corruption process and the paths it samples for each training example. Let’s instead focus on the training/regression target of these models: the marginal flow. They all minimize the difference between their predictions and the marginal flow.</p> <div class="l-body" style="text-align: center; margin-top: 0px;"> <img src="/assets/img/decentralized_diffusion/marginal_flow_int.svg" alt="DDM Overview" style="width: 80%; height: auto;"/> </div> <p>The marginal flow, \(u_t(x_t)\), represents a vector field at each timestep that transports from \(x_t\), a noisy variable, to the data distribution ($x_t$ at $t=0$). When we train with flow matching, we regress the marginal flow into a model (e.g., a Diffusion Transformer<d-cite key="peebles2023scalablediffusionmodelstransformers"></d-cite>) that can sample the data distribution. The marginal flow in its analytical form is an expectation over \(x_0\) data samples. That is, the marginal flow is linear. For any given \(x_t\), it points toward the data distribution from \(x_t\). In high dimensions with many data points, this is intractable to compute. Instead, diffusion models compress this complex system into a neural network through flow matching.</p> <div class="l-body" style="text-align: center;"> <img src="/assets/img/decentralized_diffusion/marginal_flow_sum.svg" alt="DDM Overview" style="width: 80%; height: auto;"/> </div> <p>Let’s rewrite the marginal flow as a sum over a discrete dataset for clarity. $q(x_0)$ is a constant now. It’s now easy to see that the marginal flow is just a weighted average of the paths from $x_t$ to each data point, $u_t(x_t|x_0)$. Each path $u_t(x_t|x_0)$ is called a “conditional flow,” pointing from $x_t$ to a specific data sample $x_0$. We marginalize over these conditional flows to get the marginal flow. The weights of each path are determined by the normalized probability of drawing $x_t$ from a Gaussian centered at each $x_0$ sample, $p_t(x_t|x_0)$.</p> <p>Sampling from the marginal flow is simple. At the maximum timestep $t=1$, \(x_t\) is drawn from the Gaussian distribution. Then, we can transport \(x_t\) to a sample from the data distribution by integrating the marginal flow backwards in time. This just means taking steps in the direction of the marginal flow at progressively decreasing timesteps. In other words, just keep taking small steps toward a weighted average of the data points and you’ll converge to a sample. Machine learning is effective at learning these weighted averages through reconstruction objectives. The meat of this interpretation is not new—it’s highly related to score matching<d-cite key="song2021scorebasedgenerativemodelingstochastic"></d-cite>, SDEs and Tweedie’s formula. These connections are covered much more thoroughly in this <a href="https://diffusionflow.github.io">blog post</a>.</p> <p>We highlight a new interpretation because it compactly motivates DDMs. Our interpretation is maybe the simplest way to understand the main ideas of this family of models. It also shows that these models can be geometrically intuitive. Since we can compute the marginal flow analytically over small datasets, we can visualize it interactively in 2D. We made the plot below to show how the components of flow-based models interact.</p> <p><b>In the following live plot:</b></p> <ul> <li>Data points ($x_0$ samples) are <b style="color: #323083;">dark blue</b>.</li> <li>Each path/conditional flow, $u_t(x_t|x_0)$, is drawn in <b style="color: #2cc779;">turquoise</b> and its opacity represents its weight (“path weight” above).</li> <li>The noisy latent ($x_t$) is <b style="color: #F84643;">red</b>. Drag it around to see how each training example affects the denoising path from $x_t$ to the data distribution at different values of $t$.</li> <li>The <b style="color: #F84643;">red</b> dotted line shows the predicted denoising path, AKA the marginal flow, evaluated analytically that points from $x_t$ to the weighted average of the data, $\hat{x}_0$.</li> <li>The <b>slider</b> below simulates the denoising (decreasing $t$) and the noising (increasing $t$) processes.</li> </ul> <div class="l-page"> <iframe src="/assets/plotly/plot_one.html" frameborder="0" scrolling="no" height="620px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <p><br/> Since the marginal flow is defined at each timestep, the slider updates the timestep t. $x_t$ will be transported accordingly by Euler integrating<d-cite key="song2022denoisingdiffusionimplicitmodels"></d-cite> the marginal flow forward or backward in time. The data points will also change in magnitude according to a simple linear schedule, $(1-t)*x_0$, the mean of the Gaussians that define $p_t(x_t|x_0)$. At low timesteps, the path weights are much peakier and $x_t$ will be drawn to its nearest neighbor. Play around, this simulates a “perfectly overfit” diffusion model. For example, try dragging $x_t$ around the points with the slider set to $t=0.10$.</p> <p>This interpretation sets up Decentralized Diffusion Models very naturally. <b>The marginal flow is a linear system, and linear systems are associative.</b> DDMs exploit this associativity to simplify training systems and improve downstream performance.</p> <h2 id="decentralized-diffusion-models">Decentralized Diffusion Models</h2> <p>Decentralized Diffusion Models leverage the associative property of the marginal flow to split training into many independent sub-training jobs focused on producing “flow experts” that each model a subset of the data. These have no data dependencies to each other, so they can be trained wherever compute is available.</p> <p>We partition the data into K disjoint clusters ${S_1, S_2, \ldots, S_K}$, and each expert trains on an assigned subset $(x_0 \in S_i)$. Since the marginal flow is a linear combination over data points, we can apply the associative property within each of these data clusters. We therefore rewrite the global marginal flow as a weighted combination of marginal flows over each data partition.</p> <div class="l-body" style="text-align: center;"> <img src="/assets/img/decentralized_diffusion/marginal_flow_associated.svg" alt="DDM Overview" style="width: 80%; height: auto;"/> </div> <p>We train a separate diffusion model over each individual data cluster. This is standard flow matching training, so we can reuse popular architectures, hyperparameters and codebases. By adaptively averaging each model’s prediction at test-time, we sample from the entire distribution and optimize the global flow matching objective. We must learn a router to predict the adaptive weights of each expert model at test-time, which we train with a classification objective over the data clusters. We discuss this more thoroughly in the paper.</p> <p>We can visualize the component flows of a Decentralized Diffusion Model in the plot below. By ensembling them at test-time, we recover the global marginal flow. Drag the black $x_t$ circle to see the denoising predictions for each expert model (blue and red). Slide the time slider to see how the ensembled denoising predictions update the particle $x_t$.</p> <div class="l-page"> <iframe src="/assets/plotly/plot_two.html" frameborder="0" scrolling="no" height="620px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <p><br/></p> <p>The figure below outlines the data preprocessing, training and inference stages of Decentralized Diffusion Models:</p> <div class="l-page" style="text-align: center;"> <img src="/assets/img/decentralized_diffusion/method_wide.jpg" alt="DDM Overview" style="width: 100%; height: auto;"/> </div> <div class="caption l-page"> <b>Decentralized Diffusion Models follow a three-step training process.</b> We first cluster the dataset using an off-the-shelf representation model (DINOv2). We train a diffusion model over each of these clusters and a router that associates any input $x_t$ with its most likely clusters. At test-time, given a noisy sample, each expert (in red and green) predict their own flows, which combine linearly via the weights predicted by the router. The combined flow samples the entire distribution and is illustrated on the right. </div> <h2 id="why-ddms">Why DDMs?</h2> <p>These are all cute observations, but why does it matter?</p> <p>Associativity is the key enabler behind many distributed computing algorithms including parallel scans and MapReduce. Decentralized Diffusion Models use the associative property to split diffusion training into many sub-training jobs that proceed independently, with no cross-communication. This means each training job can be assigned to a different cluster in a different location and with different hardware. For example, we train a text-to-image diffusion model on eight independent nodes (8 GPUs each) for around a week. These nodes are readily available to rent from cloud providers, whereas eight nodes with high-bandwidth interconnect must be co-located in one datacenter and are much harder (and more expensive!) to procure.</p> <div class="l-body" style="text-align: center;"> <img src="/assets/img/decentralized_diffusion/combined.jpg" alt="DDM Overview" style="width: 100%; height: auto;"/> </div> <div class="caption"> Some nice generated images from the eight-node training run. </div> <p>What’s the performance hit from this added convenience? There is none. In fact, Decentralized Diffusion Models <b>outperform non-decentralized diffusion models FLOP-for-FLOP</b>.</p> <p><br/></p> <div class="l-body" style="text-align: center; margin-top: 0px; margin-bottom: 20px;"> <img src="/assets/img/decentralized_diffusion/combined_fid_plots.png" alt="DDM Overview" style="width: 100%; height: auto; clip-path: inset(0px 0 0 0);"/> </div> <div class="caption l-body"> <b>Comparing DDMs and standard monolithic diffusion models.</b> FLOP-for-FLOP, decentralized diffusion models outperform monolith diffusion models on both ImageNet and LAION Aesthetics. </div> <p>By selecting only the most relevant expert model per step at test-time, the ensemble instantiates a sparse model. We can view this as activating only a subset of the parameters of a much larger model, resulting in better performance at the same computational cost. This is also the driving insight in Mixture-of-Experts. We use the same architectures, datasets and training hyperparameters between monoliths and DDMs in all our evaluations, and we account for the additional cost of training the router (~4%). Serving a sparse model can be inconvenient with less sophisticated infrastructure, so we also demonstrate that we can efficiently distill DDMs into monolith models in the paper.</p> <div class="l-body" style="text-align: center; margin-top: 0px; margin-bottom: 20px;"> <img src="/assets/img/decentralized_diffusion/laion_scaling_laws.svg" alt="DDM Overview" style="width: 80%; height: auto; clip-path: inset(0 0 0 0);"/> </div> <div class="caption"> <b>Decentralized diffusion models scale gracefully to billions of parameters.</b> We find that increasing expert model capacity and training compute predictably improves performance. </div> <p>Decentralized Diffusion Models also scale gracefully. We see consistent improvements on evaluations as model size and compute capacity increased. Please see the paper for more detailed analysis of DDMs and how they compare to standard diffusion training.</p> <h2 id="simple-implementation">Simple Implementation</h2> <p>Decentralized Diffusion Models integrate seamlessly into existing diffusion training environments. In implementation, DDMs involve clustering a dataset then training a standard diffusion model on each cluster. This means nearly everything from existing diffusion infrastructure can be reused. This includes training code, dataloading pipelines, systems optimizations, noise schedules and architectures.</p> <p>To highlight this, we’ve included a simple code example of how to modify a diffusion training loop to be a DDM in PyTorch.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Inside a standard diffusion training loop:
</span><span class="n">x</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x_t</span> <span class="o">=</span> <span class="nf">forward_diffuse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">x_0_pred</span> <span class="o">=</span> <span class="nf">reverse_diffuse</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">x_0_pred</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div> <p>To make this a DDM, we first cluster the dataset using a representation model. We used DINOv2<d-cite key="oquab2024dinov2learningrobustvisual"></d-cite> and <a href="https://github.com/facebookresearch/MetaCLIP/tree/main/mode">this codebase</a><d-cite key="ma2024modeclipdataexperts"></d-cite> to run k-means clustering on a large dataset. We then train a diffusion model over each cluster. This is completely unchanged from standard diffusion training like above.</p> <p>The last step is to train a router that predicts the weights of each expert model at test-time. This reduces to a classification objective over the data clusters.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Inside a DDM router training loop:
</span><span class="n">x</span><span class="p">,</span> <span class="n">cluster_idx</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x_t</span> <span class="o">=</span> <span class="nf">forward_diffuse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="nf">router</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="c1"># shape (B, num_clusters)
</span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">cluster_idx</span><span class="p">)</span>
<span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div> <p>At test-time, we can sample from the entire distribution by ensembling the experts.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Inside a naive DDM inference loop:
</span><span class="n">router_pred</span> <span class="o">=</span> <span class="nf">router</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="c1"># shape (B, num_clusters)
</span><span class="n">router_pred</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">router_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ensemble_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">):</span>
    <span class="n">model_pred</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">ensemble_pred</span> <span class="o">+=</span> <span class="n">router_pred</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">model_pred</span>

<span class="n">x_t</span> <span class="o">=</span> <span class="nf">reverse_step</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">ensemble_pred</span><span class="p">)</span>
</code></pre></div></div> <p>We can make this more efficient by inferencing experts in parallel and by using a sparse router that only activates a subset of the experts at test-time. In our comparisons, we actually just select the single most relevant expert model per step at test-time.</p> <h2 id="acknowledgements">Acknowledgements</h2> <p>We would like to thank Alex Yu for his guidance throughout the project and his score matching derivation. We would also like to thank Daniel Mendelevitch, Songwei Ge, Dan Kondratyuk, Haiwen Feng, Terrance DeVries, Chung Min Kim, Samarth Sinha, Hang Gao, Justin Kerr and the Luma AI research team for helpful discussions.</p>]]></content><author><name>David McAllister</name></author><category term="distill"/><category term="formatting"/><summary type="html"><![CDATA[Train diffusion models across many GPU clusters without networking bottlenecks.]]></summary></entry><entry><title type="html">a post with image galleries</title><link href="https://flowreinforce.github.io/blog/2024/photo-gallery/" rel="alternate" type="text/html" title="a post with image galleries"/><published>2024-12-04T01:59:00+00:00</published><updated>2024-12-04T01:59:00+00:00</updated><id>https://flowreinforce.github.io/blog/2024/photo-gallery</id><content type="html" xml:base="https://flowreinforce.github.io/blog/2024/photo-gallery/"><![CDATA[<p>The images in this post are all zoomable, arranged into different mini-galleries using different libraries.</p> <h2 id="lightbox2"><a href="https://lokeshdhakar.com/projects/lightbox2/">Lightbox2</a></h2> <p><a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p> <hr/> <h2 id="photoswipe"><a href="https://photoswipe.com/">PhotoSwipe</a></h2> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-pswp-width="1669" data-pswp-height="2500" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg" alt=""/> </a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-2500.jpg" data-pswp-width="1875" data-pswp-height="2500" data-cropped="true" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-200.jpg" alt=""/> </a> <a href="https://unsplash.com" data-pswp-src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1666" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg" alt=""/> </a> <div> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1667" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg" alt=""/> </a> </div> </div> <hr/> <h2 id="spotlight-js"><a href="https://nextapps-de.github.io/spotlight/">Spotlight JS</a></h2> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/> </a> </div> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg"/> </a> </div> <hr/> <h2 id="venobox"><a href="https://veno.es/venobox/">Venobox</a></h2> <p><a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included image galleries could look like]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://flowreinforce.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://flowreinforce.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://flowreinforce.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://flowreinforce.github.io/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://flowreinforce.github.io/blog/2024/tabs</id><content type="html" xml:base="https://flowreinforce.github.io/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="12ede203-cbe3-494f-bdc9-a709599016a6" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="12ede203-cbe3-494f-bdc9-a709599016a6" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="50c4ab88-f86d-4cf0-a82f-0f8f8ee957e7" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="50c4ab88-f86d-4cf0-a82f-0f8f8ee957e7" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="d3885a75-19c5-4012-a693-cef93fc95195" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="d3885a75-19c5-4012-a693-cef93fc95195" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://flowreinforce.github.io/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://flowreinforce.github.io/blog/2024/typograms</id><content type="html" xml:base="https://flowreinforce.github.io/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://flowreinforce.github.io/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://flowreinforce.github.io/blog/2024/post-citation</id><content type="html" xml:base="https://flowreinforce.github.io/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry><entry><title type="html">a post with pseudo code</title><link href="https://flowreinforce.github.io/blog/2024/pseudocode/" rel="alternate" type="text/html" title="a post with pseudo code"/><published>2024-04-15T00:01:00+00:00</published><updated>2024-04-15T00:01:00+00:00</updated><id>https://flowreinforce.github.io/blog/2024/pseudocode</id><content type="html" xml:base="https://flowreinforce.github.io/blog/2024/pseudocode/"><![CDATA[<p>This is an example post with some pseudo code rendered by <a href="https://github.com/SaswatPadhi/pseudocode.js">pseudocode</a>. The example presented here is the same as the one in the <a href="https://saswat.padhi.me/pseudocode.js/">pseudocode.js</a> documentation, with only one simple but important change: everytime you would use <code class="language-plaintext highlighter-rouge">$</code>, you should use <code class="language-plaintext highlighter-rouge">$$</code> instead. Also, note that the <code class="language-plaintext highlighter-rouge">pseudocode</code> key in the front matter is set to <code class="language-plaintext highlighter-rouge">true</code> to enable the rendering of pseudo code. As an example, using this code:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">pseudocode
</span><span class="sb">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Generates:</p> <pre><code class="language-pseudocode">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included pseudo code could look like]]></summary></entry><entry><title type="html">a post with code diff</title><link href="https://flowreinforce.github.io/blog/2024/code-diff/" rel="alternate" type="text/html" title="a post with code diff"/><published>2024-01-27T19:22:00+00:00</published><updated>2024-01-27T19:22:00+00:00</updated><id>https://flowreinforce.github.io/blog/2024/code-diff</id><content type="html" xml:base="https://flowreinforce.github.io/blog/2024/code-diff/"><![CDATA[<p>You can display diff code by using the regular markdown syntax:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff
</span><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")
</span></code></pre></div></div> <p>But this is difficult to read, specially if you have a large diff. You can use <a href="https://diff2html.xyz/">diff2html</a> to display a more readable version of the diff. For this, just use <code class="language-plaintext highlighter-rouge">diff2html</code> instead of <code class="language-plaintext highlighter-rouge">diff</code> for the code block language:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff2html
</span><span class="sb">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
--- a/sample.js
+++ b/sample.js
@@ -1 +1 @@
-console.log("Hello World!")
+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>If we use a longer example, for example <a href="https://github.com/rtfpessoa/diff2html/commit/c2c253d3e3f8b8b267f551e659f72b44ca2ac927">this commit from diff2html</a>, it will generate the following output:</p> <pre><code class="language-diff2html">From 2aaae31cc2a37bfff83430c2c914b140bee59b6a Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sun, 9 Oct 2016 16:41:54 +0100
Subject: [PATCH 1/2] Initial template override support

---
 scripts/hulk.js                    |  4 ++--
 src/diff2html.js                   |  3 +--
 src/file-list-printer.js           | 11 ++++++++---
 src/hoganjs-utils.js               | 29 +++++++++++++++++------------
 src/html-printer.js                |  6 ++++++
 src/line-by-line-printer.js        |  6 +++++-
 src/side-by-side-printer.js        |  6 +++++-
 test/file-list-printer-tests.js    |  2 +-
 test/hogan-cache-tests.js          | 18 +++++++++++++++---
 test/line-by-line-tests.js         |  3 +--
 test/side-by-side-printer-tests.js |  3 +--
 11 files changed, 62 insertions(+), 29 deletions(-)

diff --git a/scripts/hulk.js b/scripts/hulk.js
index 5a793c18..a4b1a4d5 100755
--- a/scripts/hulk.js
+++ b/scripts/hulk.js
@@ -173,11 +173,11 @@ function namespace(name) {
 // write a template foreach file that matches template extension
 templates = extractFiles(options.argv.remain)
   .map(function(file) {
-    var openedFile = fs.readFileSync(file, 'utf-8');
+    var openedFile = fs.readFileSync(file, 'utf-8').trim();
     var name;
     if (!openedFile) return;
     name = namespace(path.basename(file).replace(/\..*$/, ''));
-    openedFile = removeByteOrderMark(openedFile.trim());
+    openedFile = removeByteOrderMark(openedFile);
     openedFile = wrap(file, name, openedFile);
     if (!options.outputdir) return openedFile;
     fs.writeFileSync(path.join(options.outputdir, name + '.js')
diff --git a/src/diff2html.js b/src/diff2html.js
index 21b0119e..64e138f5 100644
--- a/src/diff2html.js
+++ b/src/diff2html.js
@@ -7,7 +7,6 @@

 (function() {
   var diffParser = require('./diff-parser.js').DiffParser;
-  var fileLister = require('./file-list-printer.js').FileListPrinter;
   var htmlPrinter = require('./html-printer.js').HtmlPrinter;

   function Diff2Html() {
@@ -43,7 +42,7 @@

     var fileList = '';
     if (configOrEmpty.showFiles === true) {
-      fileList = fileLister.generateFileList(diffJson, configOrEmpty);
+      fileList = htmlPrinter.generateFileListSummary(diffJson, configOrEmpty);
     }

     var diffOutput = '';
diff --git a/src/file-list-printer.js b/src/file-list-printer.js
index e408d9b2..1e0a2c61 100644
--- a/src/file-list-printer.js
+++ b/src/file-list-printer.js
@@ -8,11 +8,16 @@
 (function() {
   var printerUtils = require('./printer-utils.js').PrinterUtils;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var baseTemplatesPath = 'file-summary';
   var iconsBaseTemplatesPath = 'icon';

-  function FileListPrinter() {
+  function FileListPrinter(config) {
+    this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   FileListPrinter.prototype.generateFileList = function(diffFiles) {
@@ -38,5 +43,5 @@
     });
   };

-  module.exports.FileListPrinter = new FileListPrinter();
+  module.exports.FileListPrinter = FileListPrinter;
 })();
diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 9949e5fa..0dda08d7 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -8,18 +8,19 @@
 (function() {
   var fs = require('fs');
   var path = require('path');
-
   var hogan = require('hogan.js');

   var hoganTemplates = require('./templates/diff2html-templates.js');

-  var templatesPath = path.resolve(__dirname, 'templates');
+  var extraTemplates;

-  function HoganJsUtils() {
+  function HoganJsUtils(configuration) {
+    this.config = configuration || {};
+    extraTemplates = this.config.templates || {};
   }

-  HoganJsUtils.prototype.render = function(namespace, view, params, configuration) {
-    var template = this.template(namespace, view, configuration);
+  HoganJsUtils.prototype.render = function(namespace, view, params) {
+    var template = this.template(namespace, view);
     if (template) {
       return template.render(params);
     }
@@ -27,17 +28,16 @@
     return null;
   };

-  HoganJsUtils.prototype.template = function(namespace, view, configuration) {
-    var config = configuration || {};
+  HoganJsUtils.prototype.template = function(namespace, view) {
     var templateKey = this._templateKey(namespace, view);

-    return this._getTemplate(templateKey, config);
+    return this._getTemplate(templateKey);
   };

-  HoganJsUtils.prototype._getTemplate = function(templateKey, config) {
+  HoganJsUtils.prototype._getTemplate = function(templateKey) {
     var template;

-    if (!config.noCache) {
+    if (!this.config.noCache) {
       template = this._readFromCache(templateKey);
     }

@@ -53,6 +53,7 @@

     try {
       if (fs.readFileSync) {
+        var templatesPath = path.resolve(__dirname, 'templates');
         var templatePath = path.join(templatesPath, templateKey);
         var templateContent = fs.readFileSync(templatePath + '.mustache', 'utf8');
         template = hogan.compile(templateContent);
@@ -66,12 +67,16 @@
   };

   HoganJsUtils.prototype._readFromCache = function(templateKey) {
-    return hoganTemplates[templateKey];
+    return extraTemplates[templateKey] || hoganTemplates[templateKey];
   };

   HoganJsUtils.prototype._templateKey = function(namespace, view) {
     return namespace + '-' + view;
   };

-  module.exports.HoganJsUtils = new HoganJsUtils();
+  HoganJsUtils.prototype.compile = function(templateStr) {
+    return hogan.compile(templateStr);
+  };
+
+  module.exports.HoganJsUtils = HoganJsUtils;
 })();
diff --git a/src/html-printer.js b/src/html-printer.js
index 585d5b66..13f83047 100644
--- a/src/html-printer.js
+++ b/src/html-printer.js
@@ -8,6 +8,7 @@
 (function() {
   var LineByLinePrinter = require('./line-by-line-printer.js').LineByLinePrinter;
   var SideBySidePrinter = require('./side-by-side-printer.js').SideBySidePrinter;
+  var FileListPrinter = require('./file-list-printer.js').FileListPrinter;

   function HtmlPrinter() {
   }
@@ -22,5 +23,10 @@
     return sideBySidePrinter.generateSideBySideJsonHtml(diffFiles);
   };

+  HtmlPrinter.prototype.generateFileListSummary = function(diffJson, config) {
+    var fileListPrinter = new FileListPrinter(config);
+    return fileListPrinter.generateFileList(diffJson);
+  };
+
   module.exports.HtmlPrinter = new HtmlPrinter();
 })();
diff --git a/src/line-by-line-printer.js b/src/line-by-line-printer.js
index b07eb53c..d230bedd 100644
--- a/src/line-by-line-printer.js
+++ b/src/line-by-line-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'line-by-line';
   var iconsBaseTemplatesPath = 'icon';
@@ -19,6 +20,9 @@

   function LineByLinePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   LineByLinePrinter.prototype.makeFileDiffHtml = function(file, diffs) {
diff --git a/src/side-by-side-printer.js b/src/side-by-side-printer.js
index bbf1dc8d..5e3033b3 100644
--- a/src/side-by-side-printer.js
+++ b/src/side-by-side-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'side-by-side';
   var iconsBaseTemplatesPath = 'icon';
@@ -26,6 +27,9 @@

   function SideBySidePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   SideBySidePrinter.prototype.makeDiffHtml = function(file, diffs) {
diff --git a/test/file-list-printer-tests.js b/test/file-list-printer-tests.js
index a502a46f..60ea3208 100644
--- a/test/file-list-printer-tests.js
+++ b/test/file-list-printer-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var fileListPrinter = require('../src/file-list-printer.js').FileListPrinter;
+var fileListPrinter = new (require('../src/file-list-printer.js').FileListPrinter)();

 describe('FileListPrinter', function() {
   describe('generateFileList', function() {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 190bf6f8..3bb754ac 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var HoganJsUtils = require('../src/hoganjs-utils.js').HoganJsUtils;
+var HoganJsUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)();
 var diffParser = require('../src/diff-parser.js').DiffParser;

 describe('HoganJsUtils', function() {
@@ -21,16 +21,28 @@ describe('HoganJsUtils', function() {
       });
       assert.equal(emptyDiffHtml, result);
     });
+
     it('should render view without cache', function() {
       var result = HoganJsUtils.render('generic', 'empty-diff', {
         contentClass: 'd2h-code-line',
         diffParser: diffParser
       }, {noCache: true});
-      assert.equal(emptyDiffHtml + '\n', result);
+      assert.equal(emptyDiffHtml, result);
     });
+
     it('should return null if template is missing', function() {
-      var result = HoganJsUtils.render('generic', 'missing-template', {}, {noCache: true});
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)({noCache: true});
+      var result = hoganUtils.render('generic', 'missing-template', {});
       assert.equal(null, result);
     });
+
+    it('should allow templates to be overridden', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+
+      var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
diff --git a/test/line-by-line-tests.js b/test/line-by-line-tests.js
index 1cd92073..8869b3df 100644
--- a/test/line-by-line-tests.js
+++ b/test/line-by-line-tests.js
@@ -14,7 +14,7 @@ describe('LineByLinePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expected, fileHtml);
     });
@@ -422,7 +422,6 @@ describe('LineByLinePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                &lt;/tbody&gt;\n' +
         '            &lt;/table&gt;\n' +
         '        &lt;/div&gt;\n' +
diff --git a/test/side-by-side-printer-tests.js b/test/side-by-side-printer-tests.js
index 76625f8e..771daaa5 100644
--- a/test/side-by-side-printer-tests.js
+++ b/test/side-by-side-printer-tests.js
@@ -14,7 +14,7 @@ describe('SideBySidePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expectedRight, fileHtml.right);
       assert.equal(expectedLeft, fileHtml.left);
@@ -324,7 +324,6 @@ describe('SideBySidePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                    &lt;/tbody&gt;\n' +
         '                &lt;/table&gt;\n' +
         '            &lt;/div&gt;\n' +

From f3cadb96677d0eb82fc2752dc3ffbf35ca9b5bdb Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sat, 15 Oct 2016 13:21:22 +0100
Subject: [PATCH 2/2] Allow uncompiled templates

---
 README.md                 |  3 +++
 src/hoganjs-utils.js      |  7 +++++++
 test/hogan-cache-tests.js | 24 +++++++++++++++++++++++-
 3 files changed, 33 insertions(+), 1 deletion(-)

diff --git a/README.md b/README.md
index 132c8a28..46909f25 100644
--- a/README.md
+++ b/README.md
@@ -98,6 +98,9 @@ The HTML output accepts a Javascript object with configuration. Possible options
   - `synchronisedScroll`: scroll both panes in side-by-side mode: `true` or `false`, default is `false`
   - `matchWordsThreshold`: similarity threshold for word matching, default is 0.25
   - `matchingMaxComparisons`: perform at most this much comparisons for line matching a block of changes, default is `2500`
+  - `templates`: object with previously compiled templates to replace parts of the html
+  - `rawTemplates`: object with raw not compiled templates to replace parts of the html
+  &gt; For more information regarding the possible templates look into [src/templates](https://github.com/rtfpessoa/diff2html/tree/master/src/templates)

 ## Diff2HtmlUI Helper

diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 0dda08d7..b2e9c275 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -17,6 +17,13 @@
   function HoganJsUtils(configuration) {
     this.config = configuration || {};
     extraTemplates = this.config.templates || {};
+
+    var rawTemplates = this.config.rawTemplates || {};
+    for (var templateName in rawTemplates) {
+      if (rawTemplates.hasOwnProperty(templateName)) {
+        if (!extraTemplates[templateName]) extraTemplates[templateName] = this.compile(rawTemplates[templateName]);
+      }
+    }
   }

   HoganJsUtils.prototype.render = function(namespace, view, params) {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 3bb754ac..a34839c0 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -36,7 +36,7 @@ describe('HoganJsUtils', function() {
       assert.equal(null, result);
     });

-    it('should allow templates to be overridden', function() {
+    it('should allow templates to be overridden with compiled templates', function() {
       var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');

       var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
@@ -44,5 +44,27 @@ describe('HoganJsUtils', function() {
       var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
       assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
     });
+
+    it('should allow templates to be overridden with uncompiled templates', function() {
+      var emptyDiffTemplate = '&lt;p&gt;&lt;/p&gt;';
+
+      var config = {rawTemplates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
+
+    it('should allow templates to be overridden giving priority to compiled templates', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+      var emptyDiffTemplateUncompiled = '&lt;p&gt;Not used!&lt;/p&gt;';
+
+      var config = {
+        templates: {'generic-empty-diff': emptyDiffTemplate},
+        rawTemplates: {'generic-empty-diff': emptyDiffTemplateUncompiled}
+      };
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is how you can display code diffs]]></summary></entry></feed>